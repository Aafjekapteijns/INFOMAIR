{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/aafjekapteijns/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree, ensemble, model_selection, metrics\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import random\n",
    "import string\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data for the dialog acts and utterance contents\n",
    "dialog_acts = open(\"dialog_acts.dat\", 'r')\n",
    "\n",
    "# Read in data, convert to lowercase strings\n",
    "dialog_list = []\n",
    "for line in dialog_acts: \n",
    "    line = line.strip()\n",
    "    line = line.lower()\n",
    "    act = line.split(' ')[0]\n",
    "    cont = line[(len(act) + 1):]\n",
    "    dialog_list.append([act, cont])\n",
    "\n",
    "dialog_acts = np.array(dialog_list)\n",
    "# print(dialog_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting arrays in X and r\n",
    "def split(data):\n",
    "    return(data[:, 0, None], data[:, 1, None])\n",
    "\n",
    "acts, contents = split(dialog_acts)\n",
    "# print(acts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coens code\n",
    "\n",
    "wordfreq = {}\n",
    "for content in contents:\n",
    "    tokens = nltk.word_tokenize(content[0])\n",
    "    for token in tokens:\n",
    "        if token not in wordfreq.keys():\n",
    "            wordfreq[token] = 1\n",
    "        else:\n",
    "            wordfreq[token] += 1\n",
    "most_freq = heapq.nlargest(200, wordfreq, key=wordfreq.get)\n",
    "\n",
    "content_vectors = []\n",
    "for content in contents:\n",
    "    content_tokens = nltk.word_tokenize(content[0])\n",
    "    sent_vec = []\n",
    "    for token in most_freq:\n",
    "        if token in content_tokens:\n",
    "            sent_vec.append(1)\n",
    "        else:\n",
    "            sent_vec.append(0)\n",
    "    content_vectors.append(sent_vec)\n",
    "    \n",
    "# print(content_vectors)\n",
    "\n",
    "# for instance, label in zip(np.array(content_vectors),acts):\n",
    "#     print(instance, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in training and test set (85%, 15%)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(np.array(content_vectors), acts, test_size=0.15, train_size=0.85, random_state=0)\n",
    "\n",
    "# Check\n",
    "# print(X_train.shape)\n",
    "# print(X_train)\n",
    "# print(y_train.shape)\n",
    "# print(y_train)\n",
    "# print(X_test.shape)\n",
    "# print(X_test)\n",
    "# print(y_test.shape)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tree.DecisionTreeClassifier(random_state=0)\n",
    "param_distributions = {\"max_depth\": [x for x in range(1,1000)], \"min_samples_split\": [x for x in range(2,1000)],\n",
    "                      \"min_samples_leaf\": [x for x in range(1,1000)], \"max_leaf_nodes\": [x for x in range(2,1000)]}\n",
    "n_iter = 500\n",
    "scoring = [\"accuracy\"]\n",
    "cv = model_selection.StratifiedKFold(n_splits=2)\n",
    "refit = \"accuracy\"\n",
    "\n",
    "randomized_search_tree = model_selection.RandomizedSearchCV(estimator=estimator, param_distributions=param_distributions, n_iter=n_iter,\n",
    "                                            scoring=scoring, cv=cv, refit=refit, random_state=0)\n",
    "\n",
    "search_tree = randomized_search_tree.fit(X_train, y_train)\n",
    "results_tree = pd.DataFrame(search_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.332405      0.016682         0.114514        0.008857   \n",
      "1         0.574465      0.004066         0.135124        0.012396   \n",
      "2         0.894503      0.096034         0.131173        0.017501   \n",
      "3         0.351149      0.005995         0.123347        0.007391   \n",
      "4         0.522559      0.016429         0.122907        0.013346   \n",
      "..             ...           ...              ...             ...   \n",
      "495       0.356252      0.005467         0.130119        0.003062   \n",
      "496       0.578414      0.005903         0.115021        0.001983   \n",
      "497       0.619475      0.001912         0.119385        0.010196   \n",
      "498       0.354531      0.008458         0.111358        0.002050   \n",
      "499       0.358189      0.009827         0.116222        0.004843   \n",
      "\n",
      "    param_min_samples_split param_min_samples_leaf param_max_leaf_nodes  \\\n",
      "0                       463                    665                  999   \n",
      "1                       534                    230                  677   \n",
      "2                       653                     45                  910   \n",
      "3                       679                    914                  378   \n",
      "4                       793                    180                  541   \n",
      "..                      ...                    ...                  ...   \n",
      "495                     358                    869                  343   \n",
      "496                     893                    160                   47   \n",
      "497                     959                    109                  336   \n",
      "498                     799                    983                  613   \n",
      "499                     673                    998                  723   \n",
      "\n",
      "    param_max_depth                                             params  \\\n",
      "0               745  {'min_samples_split': 463, 'min_samples_leaf':...   \n",
      "1               509  {'min_samples_split': 534, 'min_samples_leaf':...   \n",
      "2               293  {'min_samples_split': 653, 'min_samples_leaf':...   \n",
      "3               846  {'min_samples_split': 679, 'min_samples_leaf':...   \n",
      "4                42  {'min_samples_split': 793, 'min_samples_leaf':...   \n",
      "..              ...                                                ...   \n",
      "495             669  {'min_samples_split': 358, 'min_samples_leaf':...   \n",
      "496             579  {'min_samples_split': 893, 'min_samples_leaf':...   \n",
      "497             828  {'min_samples_split': 959, 'min_samples_leaf':...   \n",
      "498             162  {'min_samples_split': 799, 'min_samples_leaf':...   \n",
      "499             491  {'min_samples_split': 673, 'min_samples_leaf':...   \n",
      "\n",
      "     split0_test_accuracy  split1_test_accuracy  mean_test_accuracy  \\\n",
      "0                0.717778              0.719915            0.718847   \n",
      "1                0.838638              0.838686            0.838662   \n",
      "2                0.918904              0.919528            0.919216   \n",
      "3                0.691023              0.691030            0.691027   \n",
      "4                0.852293              0.867756            0.860023   \n",
      "..                    ...                   ...                 ...   \n",
      "495              0.717778              0.719915            0.718847   \n",
      "496              0.885598              0.871078            0.878339   \n",
      "497              0.911246              0.913714            0.912480   \n",
      "498              0.691023              0.691030            0.691027   \n",
      "499              0.691023              0.691030            0.691027   \n",
      "\n",
      "     std_test_accuracy  rank_test_accuracy  \n",
      "0             0.001068                 263  \n",
      "1             0.000024                 108  \n",
      "2             0.000312                  22  \n",
      "3             0.000003                 448  \n",
      "4             0.007731                  92  \n",
      "..                 ...                 ...  \n",
      "495           0.001068                 263  \n",
      "496           0.007260                  80  \n",
      "497           0.001234                  34  \n",
      "498           0.000003                 448  \n",
      "499           0.000003                 448  \n",
      "\n",
      "[500 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(results_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 79, 'min_samples_leaf': 1, 'max_leaf_nodes': 74, 'max_depth': 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ack       0.00      0.00      0.00         3\n",
      "      affirm       0.99      0.98      0.99       150\n",
      "         bye       0.96      0.94      0.95        50\n",
      "     confirm       0.71      0.68      0.70        22\n",
      "        deny       0.00      0.00      0.00         3\n",
      "       hello       1.00      0.86      0.92        14\n",
      "      inform       0.94      0.98      0.96      1522\n",
      "      negate       0.97      0.97      0.97        65\n",
      "        null       0.96      0.74      0.83       244\n",
      "      repeat       0.00      0.00      0.00         5\n",
      "     reqalts       0.93      0.95      0.94       277\n",
      "     reqmore       0.00      0.00      0.00         1\n",
      "     request       0.99      0.98      0.98       973\n",
      "     restart       0.00      0.00      0.00         2\n",
      "    thankyou       0.99      0.99      0.99       495\n",
      "\n",
      "    accuracy                           0.96      3826\n",
      "   macro avg       0.63      0.60      0.62      3826\n",
      "weighted avg       0.96      0.96      0.96      3826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = search_tree.best_params_\n",
    "print(best_params)\n",
    "best_decision_tree = search_tree.best_estimator_\n",
    "\n",
    "# Predict test set\n",
    "labels_predict_search = best_decision_tree.predict(X_test)\n",
    "\n",
    "# Check metrics\n",
    "report_randomized_search = metrics.classification_report(y_test, labels_predict_search)\n",
    "print(report_randomized_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
